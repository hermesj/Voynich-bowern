"0",""
"0","# Sample documents of various sizes from the entire Voynich text"
"0",""
"0","interlinear_full_words <- read.table(paste(path_to_voy, 'interlinear_full_words.txt', sep=''), sep=""\t"", quote=""\"""", header=TRUE)"
"0",""
"0","# Full Takahashi Transcription"
"0","voynich.full.df <- interlinear_full_words[interlinear_full_words$transcriber == 'H',]"
"0",""
"0","voy.list <- as.vector(voynich.full.df$word)"
"0",""
"0","voy.samp.a1 <- concatenate(sample(voy.list, size = 11415, replace = FALSE, prob = NULL))"
"0","voy.samp.a2 <- concatenate(sample(voy.list, size = 11415, replace = FALSE, prob = NULL))"
"0",""
"0","voy.samp.b1 <- concatenate(sample(voy.list, size = 23244, replace = FALSE, prob = NULL))"
"0","voy.samp.b2 <- concatenate(sample(voy.list, size = 23244, replace = FALSE, prob = NULL))"
"0",""
"0",""
"0","write(voy.samp.a1, file = 'Voynich_texts/Voynich Sample A1', sep = """")"
"0","write(voy.samp.a2, file = 'Voynich_texts/Voynich Sample A2', sep = """")"
"0","write(voy.samp.b1, file = 'Voynich_texts/Voynich Sample B1', sep = """")"
"0","write(voy.samp.b2, file = 'Voynich_texts/Voynich Sample B2', sep = """")"
