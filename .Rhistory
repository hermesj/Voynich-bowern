rm(list=ls()) # Clear environment
source('./Entropy_Functions.R')
# Packages
library(ngram) # for ngrams
library(ggplot2) # for plots
library(stringdist) # ngram doesn't work with Hebrew characters, use 'qgrams'
library(stringr)
library(readxl)
path_to_voy <- 'Voynich_texts/'
# Create Voynich statistics dataframe
# Save the file as voystats.csv
full.voy.max <- scan('Voynich_texts/Maximal/Full Voynich Maximal', what="character", sep="\n", comment.char = "#")
full.voy.max.text <- scan('Voynich_texts/Maximal/Full Voynich Maximal Text', what="character", sep="\n", comment.char = "#")
full.voy.max.simp <- scan('Voynich_texts/Maximal Simplified/Full Voynich Maximal Simplified', what="character", sep="\n", comment.char = "#")
full.voy.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Full Voynich Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
full.voy.min <- scan('Voynich_texts/Minimal/Full Voynich Minimal', what="character", sep="\n", comment.char = "#")
full.voy.min.text <- scan('Voynich_texts/Minimal/Full Voynich Minimal Text', what="character", sep="\n", comment.char = "#")
voy.a.max <- scan('Voynich_texts/Maximal/Voynich A Maximal', what="character", sep="\n", comment.char = "#")
voy.a.max.text <- scan('Voynich_texts/Maximal/Voynich A Maximal Text', what="character", sep="\n", comment.char = "#")
voy.a.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich A Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.a.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich A Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.a.min <- scan('Voynich_texts/Minimal/Voynich A Minimal', what="character", sep="\n", comment.char = "#")
voy.a.min.text <- scan('Voynich_texts/Minimal/Voynich A Minimal Text', what="character", sep="\n", comment.char = "#")
voy.b.max <- scan('Voynich_texts/Maximal/Voynich B Maximal', what="character", sep="\n", comment.char = "#")
voy.b.max.text <- scan('Voynich_texts/Maximal/Voynich B Maximal Text', what="character", sep="\n", comment.char = "#")
voy.b.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich B Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.b.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich B Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.b.min <- scan('Voynich_texts/Minimal/Voynich B Minimal', what="character", sep="\n", comment.char = "#")
voy.b.min.text <- scan('Voynich_texts/Minimal/Voynich B Minimal Text', what="character", sep="\n", comment.char = "#")
voy.1.max <- scan('Voynich_texts/Maximal/Voynich 1 Maximal', what="character", sep="\n", comment.char = "#")
voy.1.max.text <- scan('Voynich_texts/Maximal/Voynich 1 Maximal Text', what="character", sep="\n", comment.char = "#")
voy.1.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich 1 Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.1.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich 1 Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.1.min <- scan('Voynich_texts/Minimal/Voynich 1 Minimal', what="character", sep="\n", comment.char = "#")
voy.1.min.text <- scan('Voynich_texts/Minimal/Voynich 1 Minimal Text', what="character", sep="\n", comment.char = "#")
voy.2.max <- scan('Voynich_texts/Maximal/Voynich 2 Maximal', what="character", sep="\n", comment.char = "#")
voy.2.max.text <- scan('Voynich_texts/Maximal/Voynich 2 Maximal Text', what="character", sep="\n", comment.char = "#")
voy.2.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich 2 Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.2.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich 2 Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.2.min <- scan('Voynich_texts/Minimal/Voynich 2 Minimal', what="character", sep="\n", comment.char = "#")
voy.2.min.text <- scan('Voynich_texts/Minimal/Voynich 2 Minimal Text', what="character", sep="\n", comment.char = "#")
voy.3.max <- scan('Voynich_texts/Maximal/Voynich 3 Maximal', what="character", sep="\n", comment.char = "#")
voy.3.max.text <- scan('Voynich_texts/Maximal/Voynich 3 Maximal Text', what="character", sep="\n", comment.char = "#")
voy.3.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich 3 Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.3.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich 3 Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.3.min <- scan('Voynich_texts/Minimal/Voynich 3 Minimal', what="character", sep="\n", comment.char = "#")
voy.3.min.text <- scan('Voynich_texts/Minimal/Voynich 3 Minimal Text', what="character", sep="\n", comment.char = "#")
voy.4.max <- scan('Voynich_texts/Maximal/Voynich 4 Maximal', what="character", sep="\n", comment.char = "#")
voy.4.max.text <- scan('Voynich_texts/Maximal/Voynich 4 Maximal Text', what="character", sep="\n", comment.char = "#")
voy.4.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich 4 Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.4.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich 4 Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.4.min <- scan('Voynich_texts/Minimal/Voynich 4 Minimal', what="character", sep="\n", comment.char = "#")
voy.4.min.text <- scan('Voynich_texts/Minimal/Voynich 4 Minimal Text', what="character", sep="\n", comment.char = "#")
voy.5.max <- scan('Voynich_texts/Maximal/Voynich 5 Maximal', what="character", sep="\n", comment.char = "#")
voy.5.max.text <- scan('Voynich_texts/Maximal/Voynich 5 Maximal Text', what="character", sep="\n", comment.char = "#")
voy.5.max.simp <- scan('Voynich_texts/Maximal Simplified/Voynich 5 Maximal Simplified', what="character", sep="\n", comment.char = "#")
voy.5.max.simp.text <- scan('Voynich_texts/Maximal Simplified/Voynich 5 Maximal Simplified Text', what="character", sep="\n", comment.char = "#")
voy.5.min <- scan('Voynich_texts/Minimal/Voynich 5 Minimal', what="character", sep="\n", comment.char = "#")
voy.5.min.text <- scan('Voynich_texts/Minimal/Voynich 5 Minimal Text', what="character", sep="\n", comment.char = "#")
voys <- c(full.voy.max, full.voy.max.text, full.voy.max.simp, full.voy.max.simp.text, full.voy.min, full.voy.min.text, voy.a.max, voy.a.max.text, voy.a.max.simp, voy.a.max.simp.text, voy.a.min, voy.a.min.text, voy.b.max, voy.b.max.text, voy.b.max.simp, voy.b.max.simp.text, voy.b.min, voy.b.min.text, voy.1.max, voy.1.max.text, voy.1.max.simp, voy.1.max.simp.text, voy.1.min, voy.1.min.text, voy.2.max, voy.2.max.text, voy.2.max.simp, voy.2.max.simp.text, voy.2.min, voy.2.min.text, voy.3.max, voy.3.max.text, voy.3.max.simp, voy.3.max.simp.text, voy.3.min, voy.3.min.text, voy.4.max, voy.4.max.text, voy.4.max.simp, voy.4.max.simp.text, voy.4.min, voy.4.min.text, voy.5.max, voy.5.max.text, voy.5.max.simp, voy.5.max.simp.text, voy.5.min, voy.5.min.text)
langs <- c('Full Voynich Maximal', 'Full Voynich Maximal Text', 'Full Voynich Maximal Simplified', 'Full Voynich Maximal Simplified Text', 'Full Voynich Minimal', 'Full Voynich Minimal Text', 'Voynich A Maximal', 'Voynich A Maximal Text', 'Voynich A Maximal Simplified', 'Voynich A Maximal Simplified Text', 'Voynich A Minimal', 'Voynich A Minimal Text', 'Voynich B Maximal', 'Voynich B Maximal Text', 'Voynich B Maximal Simplified', 'Voynich B Maximal Simplified Text', 'Voynich B Minimal', 'Voynich B Minimal Text', 'Voynich 1 Maximal', 'Voynich 1 Maximal Text', 'Voynich 1 Maximal Simplified', 'Voynich 1 Maximal Simplified Text', 'Voynich 1 Minimal', 'Voynich 1 Minimal Text', 'Voynich 2 Maximal', 'Voynich 2 Maximal Text', 'Voynich 2 Maximal Simplified', 'Voynich 2 Maximal Simplified Text', 'Voynich 2 Minimal', 'Voynich 2 Minimal Text', 'Voynich 3 Maximal', 'Voynich 3 Maximal Text', 'Voynich 3 Maximal Simplified', 'Voynich 3 Maximal Simplified Text', 'Voynich 3 Minimal', 'Voynich 3 Minimal Text', 'Voynich 4 Maximal', 'Voynich 4 Maximal Text', 'Voynich 4 Maximal Simplified', 'Voynich 4 Maximal Simplified Text', 'Voynich 4 Minimal', 'Voynich 4 Minimal Text', 'Voynich 5 Maximal', 'Voynich 5 Maximal Text', 'Voynich 5 Maximal Simplified', 'Voynich 5 Maximal Simplified Text', 'Voynich 5 Minimal', 'Voynich 5 Minimal Text')
codes <- c('voy.f.com', 'voy.f.com.text', 'voy.f', 'voy.f.text', 'voy.f.min', 'voy.f.min.text', 'voy.a.com', 'voy.a.com.text', 'voy.a', 'voy.a.text', 'voy.a.min', 'voy.a.min.text', 'voy.b.com', 'voy.b.com.text', 'voy.b', 'voy.b.text', 'voy.b.min', 'voy.b.min.text', 'voy.1.com', 'voy.1.com.text', 'voy.1', 'voy.1.text', 'voy.1.min', 'voy.1.min.text', 'voy.2.com', 'voy.2.com.text', 'voy.2', 'voy.2.text', 'voy.2.min', 'voy.2.min.text', 'voy.3.com', 'voy.3.com.text', 'voy.3', 'voy.3.text', 'voy.3.min', 'voy.3.min.text', 'voy.4.com', 'voy.4.com.text', 'voy.4', 'voy.4.text', 'voy.4.min', 'voy.4.min.text', 'voy.5.com', 'voy.5.com.text', 'voy.5', 'voy.5.text', 'voy.5.min', 'voy.5.min.text')
fams <- rep('Voynich', 48)
scripts <- rep('Voynich', 48)
df <- data.frame()
for (v in voys) {
doc <- v
doc.df <- multi_stats(doc)
df <- rbind(df, doc.df)
}
df <- cbind(langs, codes, fams, scripts, df)
# Save the file
write.csv(df, file='Voynich_texts/voy_stats.csv', row.names=FALSE)
rm(list=ls()) # Clear environment
# Custom Entropy functions: sumentropy, condbigram, condtrigram, rep.seqs
source('./Entropy_Functions.R')
# Packages
library(ngram) # for ngrams
library(ggplot2) # for plots
library(stringdist) # ngram doesn't work with Hebrew characters, use 'qgrams'
library(stringr)
path_to_manuscripts <- 'Historical_texts/original/'
path_to_goal <- 'Historical_texts/cleaned/'
### This is a function which goes through texts and deletes uncommon letters
### The default threshold is .01%
delete_uncommon_chars <- function (s, thresh = .0001) {
char.table <- table(unlist(strsplit(s, "")))
char.rat.table <- char.table / sum(char.table)
s.del <- s
for (c in names(char.rat.table)) {
if (char.rat.table[c] <= thresh) {
print(c)
s.del <- str_remove_all(s.del, c)
}
}
return (s.del)
}
# English Secreta Secretorum
secr <- scan(paste(path_to_manuscripts, 'Secreta_Secretorum_ENG', sep=''), what="character", sep="\n", comment.char = "#")
secr = concatenate(secr)
str_length(secr)
secr.clean <- tolower(secr)
secr.clean <- gsub("[\\(\\);:\\.,\\'`\\?]", '', secr.clean)
secr.clean <- gsub("\\]", '', secr.clean)
secr.clean <- gsub("\\[", '', secr.clean)
secr.clean <- delete_uncommon_chars(secr.clean)
#char.table1 <- table(unlist(strsplit(secr.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
sumentropy(secr.clean)
# Codex Wormianus
worm.fac <- scan(paste(path_to_manuscripts, "Codex_Wormianus_fac", sep=''), what="character", sep="\n", comment.char = "#")
worm.fac = concatenate(worm.fac)
worm.dip <- scan(paste(path_to_manuscripts, "Codex_Wormianus_dip", sep=''), what="character", sep="\n", comment.char = "#")
worm.dip = concatenate(worm.dip)
worm.fac.clean <- tolower(worm.fac)
worm.fac.clean <- gsub('\\[', '', worm.fac.clean)
worm.fac.clean <- gsub('\\]', '', worm.fac.clean)
worm.fac.clean <- gsub('[0-9\\.]', '', worm.fac.clean)
worm.fac.clean <- gsub(' {2,}', ' ', worm.fac.clean)
worm.fac.clean <- gsub('[\\?]', '', worm.fac.clean)
worm.fac.clean <- delete_uncommon_chars(worm.fac.clean)
worm.dip.clean <- tolower(worm.dip)
worm.dip.clean <- gsub('\\[', '', worm.dip.clean)
worm.dip.clean <- gsub('\\]', '', worm.dip.clean)
worm.dip.clean <- gsub('[0-9\\.]', '', worm.dip.clean)
worm.dip.clean <- gsub(' {2,}', ' ', worm.dip.clean)
worm.dip.clean <- gsub('[\\?]', '', worm.dip.clean)
worm.dip.clean <- delete_uncommon_chars(worm.dip.clean)
#str_length(worm.dip.clean) / str_length(worm.dip)
#str_length(worm.fac.clean) / str_length(worm.fac)
#char.table1 <- table(unlist(strsplit(worm.fac.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
# Necrologium Lundense
necr.fac <- scan(paste(path_to_manuscripts, "Necrologium_fac.txt", sep=''), what="character", sep="\n", comment.char = "#")
necr.fac = concatenate(necr.fac)
necr.dip <- scan(paste(path_to_manuscripts, "Necrologium_dip.txt", sep=''), what="character", sep="\n", comment.char = "#")
necr.dip = concatenate(necr.dip)
necr.fac.clean <- tolower(necr.fac)
necr.fac.clean <- gsub('\\[', '', necr.fac.clean)
necr.fac.clean <- gsub('\\]', '', necr.fac.clean)
necr.fac.clean <- gsub('[0-9\\.]', '', necr.fac.clean)
necr.fac.clean <- gsub(' {2,}', ' ', necr.fac.clean)
necr.fac.clean <- gsub('[\\?]', '', necr.fac.clean)
necr.fac.clean <- delete_uncommon_chars(necr.fac.clean)
necr.dip.clean <- tolower(necr.dip)
necr.dip.clean <- gsub('\\[', '', necr.dip.clean)
necr.dip.clean <- gsub('\\]', '', necr.dip.clean)
necr.dip.clean <- gsub('[0-9\\.]', '', necr.dip.clean)
necr.dip.clean <- gsub(' {2,}', ' ', necr.dip.clean)
necr.dip.clean <- gsub('[\\?]', '', necr.dip.clean)
necr.dip.clean <- delete_uncommon_chars(necr.dip.clean)
#str_length(necr.dip.clean) / str_length(necr.dip)
#str_length(necr.fac.clean) / str_length(necr.fac)
#char.table1 <- table(unlist(strsplit(necr.dip, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
#char.table1
# Cirurgie
cir <- scan(paste(path_to_manuscripts, "Cirurgie", sep=''), what="character", sep="\n", comment.char = "#")
cir.clean <- cir[!grepl('^Page', cir)] # Exclude the Page No. lines
cir.clean <- gsub('\\[[^]]*\\]', '', cir.clean) # Delete everything between brackets (deletes some text but mostly notes)
cir.clean <- gsub('\\([^]]*\\)', '', cir.clean) # Same for parentheses
cir.clean <- tolower(cir.clean)
cir.clean <- gsub('[0-9]', '', cir.clean)
cir.clean <- gsub('[¶/,:\\.;\\*\\"—\\?\\}\\{}]', '', cir.clean)
cir.clean <- gsub('\\{illustration\\}', '', cir.clean)
cir.clean <- gsub('\\]', '', cir.clean)
cir.clean <- gsub('-', '', cir.clean)
cir.clean <- gsub('\\[', '', cir.clean)
cir.clean <- gsub("'", '', cir.clean)
cir.clean <- gsub(' {2,}', ' ', cir.clean)
cir.clean <- delete_uncommon_chars(cir.clean)
cir.clean <- concatenate(cir.clean, collapse="")
#char.table1 <- table(unlist(strsplit(cir.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
# Casebook
case_dip <- scan(paste(path_to_manuscripts, "Casebook_dip", sep=''), what="character", sep="\n", comment.char = "#")
case_norm <- scan(paste(path_to_manuscripts, "Casebook_norm", sep=''), what="character", sep="\n", comment.char = "#")
case_norm.clean <- tolower(case_norm)
case_norm.clean <- gsub('\\{[0-9a-z ]*\\}','',case_norm.clean)
case_norm.clean <- gsub('<[0-9a-z\\. ]*>','',case_norm.clean)
case_norm.clean <- gsub('\\[(partial )?(blank )?astrological chart\\]','',case_norm.clean)
case_norm.clean <- gsub('[\\.\\\\/:\\?\\(\\),’]', '', case_norm.clean)
case_norm.clean <- gsub(' {2,}', ' ', case_norm.clean)
case_norm.clean <- delete_uncommon_chars(case_norm.clean)
case_norm.clean <- concatenate(case_norm.clean, collapse="")
case_dipl.clean <- tolower(case_dip)
case_dipl.clean <- gsub('\\{[0-9a-z ]*\\}','',case_dipl.clean)
case_dipl.clean <- gsub('<[0-9a-z\\. ]*>','',case_dipl.clean)
case_dipl.clean <- gsub('\\[(partial )?(blank )?astrological chart\\]','',case_dipl.clean)
case_dipl.clean <- gsub('[\\.\\\\/:,’(\\?]', '', case_dipl.clean)
case_dipl.clean <- gsub(' {2,}', ' ', case_dipl.clean)
case_dipl.clean <- delete_uncommon_chars(case_dipl.clean)
case_dipl.clean <- concatenate(case_dipl.clean, collapse="")
#char.table1 <- table(unlist(strsplit(case_norm.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
# Funeral Prayer
fun <- scan(paste(path_to_manuscripts, "Funeral Prayer", sep=''), what="character", sep="\n", comment.char = "#")
fun.clean <- tolower(fun)
fun.clean <- gsub('\\[[^]]*\\]', '', fun.clean) # Delete everything between brackets (deletes some text but mostly notes)
fun.clean <- gsub('\\([^)]*\\)', '', fun.clean)
fun.clean <- gsub('[-\\.,:]', '', fun.clean)
fun.clean <- gsub(' {2,}', ' ', fun.clean)
fun.clean <- concatenate(fun.clean, collapse="")
#HEBREW
mish <- scan(paste(path_to_manuscripts, "Hebrew_Mishneh", sep=''), what="character", sep="\n", comment.char = "#")
mish.clean <- gsub("[;,'׃\\.>\\(\\)]", '', mish)
mish.clean <- gsub('"', '', mish.clean)
mish.clean <- gsub('\\-', '', mish.clean)
mish.clean <- gsub('\\[', '', mish.clean)
mish.clean <- gsub('\\]', '', mish.clean)
mish.clean <- concatenate(mish.clean, collapse="")
mish.clean <- gsub(' {2,}', ' ', mish.clean)
mish.clean <- delete_uncommon_chars(mish.clean)
ber <-  scan(paste(path_to_manuscripts, "Hebrew_Bereshit", sep=''), what="character", sep="\n", comment.char = "#")
ber.clean <- gsub('[0-9׃\\*=]', '', ber)
ber.clean <- gsub('\\[', '', ber.clean)
ber.clean <- gsub('\\]', '', ber.clean)
ber.clean <- concatenate(ber.clean, collapse="")
ber.clean <- gsub(' {2,}', ' ', ber.clean)
ber.clean <- delete_uncommon_chars(ber.clean)
ber.v <-  scan(paste(path_to_manuscripts, "Hebrew_Bereshit_vowel", sep=''), what="character", sep="\n", comment.char = "#")
ber.v.clean <- gsub('[0-9׃\\*=]', '', ber.v)
ber.v.clean <- gsub('\\[', '', ber.v.clean)
ber.v.clean <- gsub('\\]', '', ber.v.clean)
ber.v.clean <- concatenate(ber.v.clean, collapse="")
ber.v.clean <- gsub(' {2,}', ' ', ber.v.clean)
ber.v.clean <- delete_uncommon_chars(ber.v.clean)
#char.table1 <- table(unlist(strsplit(ber.v.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
# LATIN
adso <-  scan(paste(path_to_manuscripts, "Latin_Adso", sep=''), what="character", sep="\n", comment.char = "#")
aix <-  scan(paste(path_to_manuscripts, "Latin_Aix", sep=''), what="character", sep="\n", comment.char = "#")
adso.clean <- tolower(adso)
adso.clean <- gsub('[:",\\.]', '', adso.clean)
adso.clean <- gsub('\\[', '', adso.clean)
adso.clean <- gsub('\\]', '', adso.clean)
adso.clean <- gsub('\\-', '', adso.clean)
adso.clean <- gsub(' {2,}', ' ', adso.clean)
adso.clean <- delete_uncommon_chars(adso.clean)
adso.clean <- concatenate(adso.clean, collapse="")
aix.clean <- tolower(aix)
aix.clean <- gsub('\\[[0-9]*[a-z]\\]', '', aix.clean)
aix.clean <- gsub('[01«»\\(\\)\\?:;\\.,\\!\\*]', '', aix.clean)
aix.clean <- gsub('\\-', '', aix.clean)
aix.clean <- gsub(' {2,}', ' ', aix.clean)
aix.clean <- delete_uncommon_chars(aix.clean)
aix.clean <- concatenate(aix.clean, collapse="")
#char.table1 <- table(unlist(strsplit(aix.clean, "")))
#length(char.table1)
#x <- char.table1[order(char.table1, decreasing=TRUE)]
#x
# ADDITIONAL TEXTS FROM THE WORD2VEC FILES
# LATIN
# Secreta Secretorum
secr.lat <-  scan(paste(path_to_manuscripts, "Secreta_Secretorum_LAT", sep=''), what="character", sep="\n", comment.char = "#")
secr.lat <- concatenate(secr.lat)
secr.lat.clean <- tolower(secr.lat)
secr.lat.clean <- gsub('[:",\\.;\\(\\)|0-9/—\\?\\!\\^<>‹›«□▴☌☍\u26b9\ufeff]', ' ', secr.lat.clean)
secr.lat.clean <- gsub('\\[', ' ', secr.lat.clean)
secr.lat.clean <- gsub('\\]', ' ', secr.lat.clean)
secr.lat.clean <- gsub('\\-', ' ', secr.lat.clean)
secr.lat.clean <- gsub('\\t', ' ', secr.lat.clean)
secr.lat.clean <- gsub("'", ' ', secr.lat.clean)
secr.lat.clean <- gsub(' {2,}', ' ', secr.lat.clean)
secr.lat.clean <- delete_uncommon_chars(secr.lat.clean)
secr.lat.clean <- concatenate(secr.lat.clean, collapse="")
# De Magia
bruno <-  scan(paste(path_to_manuscripts, "BrunoDeMagia", sep=''), what="character", sep="\n", comment.char = "#")
bruno <- concatenate(bruno)
bruno.clean <- tolower(bruno)
bruno.clean <- gsub('[:",\\.\\^;\\(\\)|0-9/—\\?§\\*]', '', bruno.clean)
bruno.clean <- gsub("'", '', bruno.clean)
bruno.clean <- gsub('\\[', '', bruno.clean)
bruno.clean <- gsub('\\]', '', bruno.clean)
bruno.clean <- gsub('\\-', '', bruno.clean)
bruno.clean <- gsub('\\t', '', bruno.clean)
bruno.clean <- gsub(' {2,}', ' ', bruno.clean)
bruno.clean <- delete_uncommon_chars(bruno.clean)
bruno.clean <- concatenate(bruno.clean, collapse="")
# Steganographia
steg <-  scan(paste(path_to_manuscripts, "Steganographia", sep=''), what="character", sep="\n", comment.char = "#")
steg <- concatenate(steg)
steg.clean <- tolower(steg)
steg.clean <- gsub('[:",\\.;\\(\\)|0-9/—\\?`*>\\+áé\\-]', '', steg.clean)
steg.clean <- gsub("'", '', steg.clean)
steg.clean <- gsub('\\[', '', steg.clean)
steg.clean <- gsub('\\]', '', steg.clean)
steg.clean <- gsub('\\-', '', steg.clean)
steg.clean <- gsub('\\t', '', steg.clean)
steg.clean <- gsub('a~', 'ã', steg.clean)
steg.clean <- gsub('e~', 'ẽ', steg.clean)
steg.clean <- gsub('i~', 'ĩ', steg.clean)
steg.clean <- gsub('o~', 'õ', steg.clean)
steg.clean <- gsub('u~', 'ũ', steg.clean)
steg.clean <- gsub('q~', 'q̃', steg.clean)
steg.clean <- gsub(' {2,}', ' ', steg.clean)
steg.clean <- delete_uncommon_chars(steg.clean)
steg.clean <- concatenate(steg.clean, collapse="")
# MIDDLE ENGLISH
# Alphabet of Tales
alpha <-  scan(paste(path_to_manuscripts, "AlphabetOfTales", sep=''), what="character", sep="\n", comment.char = "#")
alpha <- concatenate(alpha)
alpha.clean <- tolower(alpha)
alpha.clean <- gsub('\\[[^]]*\\]', '', alpha.clean) # Delete everything between brackets (deletes expanded abbreviations and MS notes)
alpha.clean <- gsub('[:",\\.;\\(\\)|0-9/—\\?`¶=\\!]', '', alpha.clean)
alpha.clean <- gsub("'", ' ', alpha.clean)
alpha.clean <- gsub(' {2,}', ' ', alpha.clean)
alpha.clean <- gsub('\\[', '', alpha.clean)
alpha.clean <- gsub('\\]', '', alpha.clean)
alpha.clean <- gsub('\\-', '', alpha.clean)
alpha.clean <- delete_uncommon_chars(alpha.clean)
alpha.clean <- concatenate(alpha.clean, collapse="")
# Agrippa Book 1
agrippa <-  scan(paste(path_to_manuscripts, "Agrippa_book1", sep=''), what="character", sep="\n", comment.char = "#")
agrippa <- concatenate(agrippa)
agrippa.clean <- tolower(agrippa)
agrippa.clean <- gsub('[:",\\.;\\(\\)|0-9/—\\?`¶=\\!÷öáàâãåäçéèëìîñòôøúùð\\*<>\\-]', '', agrippa.clean)
agrippa.clean <- gsub("'", '', agrippa.clean)
agrippa.clean <- gsub('\\[', '', agrippa.clean)
agrippa.clean <- gsub('\\]', '', agrippa.clean)
agrippa.clean <- gsub('\\-', '', agrippa.clean)
agrippa.clean <- gsub('\\t', '', agrippa.clean)
agrippa.clean <- delete_uncommon_chars(agrippa.clean)
agrippa.clean <- gsub(' {2,}', ' ', agrippa.clean)
agrippa.clean <- concatenate(agrippa.clean, collapse="")
# SPANISH
# Picatrix
pica <-  scan(paste(path_to_manuscripts, "Picatrix", sep=''), what="character", sep="\n", comment.char = "#")
pica <- concatenate(pica)
pica.clean <- tolower(pica)
pica.clean <- gsub('[:",\\.;\\(\\)|0-9/—\\?`¡»¿«=\\!º^]', '', pica.clean)
pica.clean <- gsub('\\[', '', pica.clean)
pica.clean <- gsub('\\]', '', pica.clean)
pica.clean <- gsub('\\-', '', pica.clean)
pica.clean <- gsub('\\t', '', pica.clean)
pica.clean <- delete_uncommon_chars(pica.clean)
pica.clean <- gsub(' {2,}', '', pica.clean)
pica.clean <- concatenate(pica.clean, collapse="")
# ITALIAN
# Rettorica
rett <-  scan(paste(path_to_manuscripts, "Old Italian Rettorica.txt", sep=''), what="character", sep="\n", comment.char = "#")
rett.clean <- concatenate(rett)
rett.clean <- tolower(rett.clean)
rett.clean <- gsub('((page: )|(line: )|(paragraph: )|(section: ))', '', rett.clean)
rett.clean <- gsub('(chapter: )[ixv]*', '', rett.clean)
rett.clean <- gsub("[»«,;\\?\\.·:\\(\\)0-9']", '', rett.clean)
rett.clean <- gsub('\\[', '', rett.clean)
rett.clean <- gsub('\\]', '', rett.clean)
rett.clean <- gsub('\\-', '', rett.clean)
rett.clean <- gsub(' {2,}', '', rett.clean)
rett.clean <- delete_uncommon_chars(rett.clean)
# GEORGIAN
# Amirandar
amir <- scan(paste(path_to_manuscripts, "Georgian Amirandar.txt", sep=''), what="character", sep="\n", comment.char = "#")
amir.clean <- concatenate(amir)
amir.clean <- gsub('[^\u10A0-\u10FF ]', '', amir.clean) # Filter out anything not in the Georgian script range
amir.clean <- gsub(' {2,}', '', amir.clean)
# PERSIAN
# Sindbad
sind <- scan(paste(path_to_manuscripts, "Persian Sindbad.txt", sep=''), what="character", sep="\n", comment.char = "#")
sind.clean <- concatenate(sind)
sind.clean <- gsub('[^\u0600-\u06FF\u08A0-\u08FF ﴽﷲ]', '', sind.clean) # Filter out all but Arabic and Extended Arabic
sind.clean <- gsub(' {2,}', '', sind.clean)
# WRITE CLEANED FILES
write(secr.clean, file = paste(path_to_goal, 'Secreta_Secretorum_ENG', sep=''), sep = "")
write(worm.fac.clean, file = paste(path_to_goal, 'Codex_Wormianus_fac', sep=''), sep = "")
write(worm.dip.clean, file = paste(path_to_goal, 'Codex_Wormianus_dip', sep=''), sep = "")
write(cir.clean, file = paste(path_to_goal, 'Cirurgie', sep=''), sep = "")
write(case_norm.clean, file = paste(path_to_goal, 'Casebook_norm', sep=''), sep = "")
write(case_dipl.clean, file = paste(path_to_goal, 'Casebook_diplomatic', sep=''), sep = "")
#write(fun.clean, file = paste(path_to_goal, 'Hungarian_Funeral', sep=''), sep = "")
write(mish.clean, file = paste(path_to_goal, 'Hebrew_Mishneh', sep=''), sep = "")
write(ber.clean, file = paste(path_to_goal, 'Hebrew_Bereshit', sep=''), sep = "")
write(ber.v.clean, file = paste(path_to_goal, 'Hebrew_Bereshit_vowel', sep=''), sep = "")
write(adso.clean, file = paste(path_to_goal, 'Latin_Adso', sep=''), sep = "")
write(aix.clean, file = paste(path_to_goal, 'Latin_Aix', sep=''), sep = "")
write(secr.lat.clean, file = paste(path_to_goal, 'Secreta_Secretorum_LAT', sep=''), sep = "")
write(bruno.clean, file = paste(path_to_goal, 'BrunoDeMagia', sep=''), sep = "")
write(steg.clean, file = paste(path_to_goal, 'Steganographia', sep=''), sep = "")
write(agrippa.clean, file = paste(path_to_goal, 'Agrippa_Book1', sep=''), sep = "")
write(alpha.clean, file = paste(path_to_goal, 'AlphabetOfTales', sep=''), sep = "")
write(pica.clean, file = paste(path_to_goal, 'Picatrix', sep=''), sep = "")
write(necr.dip.clean, file = paste(path_to_goal, 'Necrologium_dip', sep=''), sep = "")
write(necr.fac.clean, file = paste(path_to_goal, 'Necrologium_fac', sep=''), sep = "")
write(rett.clean, file = paste(path_to_goal, 'Rettorica', sep=''), sep = "")
write(amir.clean, file = paste(path_to_goal, 'Amirandar', sep=''), sep = "")
write(sind.clean, file = paste(path_to_goal, 'Sindbad', sep=''), sep = "")
rm(list=ls()) # Clear environment
# Custom Entropy functions: sumentropy, condbigram, condtrigram, rep.seqs
source('./Entropy_Functions.R')
# Packages
library(ngram) # for ngrams
library(ggplot2) # for plots
library(stringdist) # ngram doesn't work with Hebrew characters, use 'qgrams'
library(stringr)
path_to_goal <- 'Historical_texts/cleaned/'
secr <- scan(paste(path_to_goal, 'Secreta_Secretorum_ENG', sep=''), what="character", sep="\n", comment.char = "#")
worm.fac <- scan(paste(path_to_goal, 'Codex_Wormianus_fac', sep=''), what="character", sep="\n", comment.char = "#")
worm.dip <- scan(paste(path_to_goal, 'Codex_Wormianus_dip', sep=''), what="character", sep="\n", comment.char = "#")
cir <- scan(paste(path_to_goal, 'Cirurgie', sep=''), what="character", sep="\n", comment.char = "#")
case_norm <- scan(paste(path_to_goal, 'Casebook_norm', sep=''), what="character", sep="\n", comment.char = "#")
case_dip <- scan(paste(path_to_goal, 'Casebook_diplomatic', sep=''), what="character", sep="\n", comment.char = "#")
#fun <- scan(paste(path_to_goal, 'Hungarian_Funeral', sep=''), what="character", sep="\n", comment.char = "#")
mish <- scan(paste(path_to_goal, 'Hebrew_Mishneh', sep=''), what="character", sep="\n", comment.char = "#")
ber <- scan(paste(path_to_goal, 'Hebrew_Bereshit', sep=''), what="character", sep="\n", comment.char = "#")
ber.v <- scan(paste(path_to_goal, 'Hebrew_Bereshit_vowel', sep=''), what="character", sep="\n", comment.char = "#")
adso <- scan(paste(path_to_goal, 'Latin_Adso', sep=''), what="character", sep="\n", comment.char = "#")
aix <- scan(paste(path_to_goal, 'Latin_Aix', sep=''), what="character", sep="\n", comment.char = "#")
secr.lat <- scan(paste(path_to_goal, 'Secreta_Secretorum_LAT', sep=''), what="character", sep="\n", comment.char = "#")
bruno <- scan(paste(path_to_goal, 'BrunoDeMagia', sep=''), what="character", sep="\n", comment.char = "#")
steg <- scan(paste(path_to_goal, 'Steganographia', sep=''), what="character", sep="\n", comment.char = "#")
agrippa <- scan(paste(path_to_goal, 'Agrippa_Book1', sep=''), what="character", sep="\n", comment.char = "#")
alpha <- scan(paste(path_to_goal, 'AlphabetOfTales', sep=''), what="character", sep="\n", comment.char = "#")
pica <- scan(paste(path_to_goal, 'Picatrix', sep=''), what="character", sep="\n", comment.char = "#")
necr.fac <- scan(paste(path_to_goal, 'Necrologium_fac', sep=''), what="character", sep="\n", comment.char = "#")
necr.dip <- scan(paste(path_to_goal, 'Necrologium_dip', sep=''), what="character", sep="\n", comment.char = "#")
rett <- scan(paste(path_to_goal, 'Rettorica', sep=''), what="character", sep="\n", comment.char = "#")
amir <- scan(paste(path_to_goal, 'Amirandar', sep=''), what="character", sep="\n", comment.char = "#")
sind <- scan(paste(path_to_goal, 'Sindbad', sep=''), what="character", sep="\n", comment.char = "#")
# Create a dataframe of overall statistics about the files
hist.files <- c(secr, worm.fac, worm.dip, cir, case_norm, case_dip, mish, ber, ber.v, adso, aix, secr.lat, bruno, steg, agrippa, alpha, pica, necr.fac, necr.dip, rett, amir, sind)
langs <-c('Secreta_Secretorum_ENG', 'Codex_Wormianus_fac', 'Codex_Wormianus_dip', 'Cirurgie', 'Casebook_norm', 'Casebook_diplomatic', 'Hebrew_Mishneh', 'Hebrew_Bereshit', 'Hebrew_Bereshit_vowel', 'Latin_Adso', 'Latin_Aix', 'Secreta_Secretorum_LAT', 'BrunoDeMagia', 'Steganographia', 'Agrippa_Book1', 'AlphabetOfTales', 'Picatrix', 'Necrologium_fac', 'Necrologium_dip', 'Rettorica', 'Amirandar', 'Sindbad')
codes <- c('secr.eng', 'worm.fac', 'form.dip', 'cir', 'case.norm', 'case.dip', 'mish', 'ber', 'ber.v', 'adso', 'aix', 'secr.lat', 'bruno', 'steg', 'agr', 'alpha', 'pic', 'necr.fac', 'necr.dip', 'rett', 'amir', 'sind')
fams <- c('English', 'Icelandic', 'Icelandic', 'English', 'English', 'English',  'Hebrew', 'Hebrew', 'Hebrew', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'English', 'English', 'Spanish', 'Latin', 'Latin', 'Italian', 'Georgian', 'Persian')
scripts <- c('Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Hebrew', 'Hebrew', 'Hebrew', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Latin', 'Georgian', 'Arabic')
df <- data.frame()
for (i in 1:length(hist.files)) {
print(paste(round(i/length(hist.files)*100,2), '% complete', sep=''))
doc <- hist.files[i]
doc.df <- multi_stats(doc)
df <- rbind(df, doc.df)
}
df <- cbind(langs, codes, fams, scripts, df)
write.csv(df, file='Historical_texts/hist_stats.csv', row.names=FALSE)
setwd("~/GitHub/R_Voynich_Stats/code")
